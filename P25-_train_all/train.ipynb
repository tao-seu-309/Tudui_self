{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 完整的模型训练套路(一)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "训练数据集长度为:{} 50000\n",
      "测试数据集长度为:{} 10000\n",
      "<class 'list'> ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
      "标签 0: airplane\n",
      "标签 1: automobile\n",
      "标签 2: bird\n",
      "标签 3: cat\n",
      "标签 4: deer\n",
      "标签 5: dog\n",
      "标签 6: frog\n",
      "标签 7: horse\n",
      "标签 8: ship\n",
      "标签 9: truck\n"
     ]
    }
   ],
   "source": [
    "# 准备数据集\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from model import *\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_data = torchvision.datasets.CIFAR10(root=\"../../dataset\",train=True,transform=torchvision.transforms.ToTensor(),\n",
    "                                          download=True)\n",
    "test_data = torchvision.datasets.CIFAR10(root=\"../../dataset\",train=False,transform=torchvision.transforms.ToTensor(),\n",
    "                                          download=True)\n",
    "\n",
    "# 查看数据集大小 length 长度\n",
    "train_data_size = len(train_data)\n",
    "test_data_size  = len(test_data)\n",
    "print(\"训练数据集长度为:{}\",format(train_data_size))\n",
    "print(\"测试数据集长度为:{}\",format(test_data_size))\n",
    "\n",
    "# 利用 DataLoader 来加载数据集\n",
    "train_dataloader = DataLoader(train_data,batch_size=64)\n",
    "test_dataloader = DataLoader(test_data,batch_size=64)\n",
    "\n",
    "# ###### 打印所有标签\n",
    "# labels = set(train_data.targets)\n",
    "# print(\"所有标签列表:\", labels)\n",
    "\n",
    "###### 打印标签与类别名称的对应关系\n",
    "## <class 'list'> ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "print(type(train_data.classes), train_data.classes)\n",
    "\n",
    "for index, class_name in enumerate(train_data.classes):\n",
    "    print(f\"标签 {index}: {class_name}\")\n",
    "    \n",
    "\n",
    "# ###### 从 DataLoader 中获取一条数据\n",
    "# for images, labels in train_dataloader:\n",
    "#     sample_image = images[0]  # 获取第一张图片\n",
    "#     sample_label = labels[0]   # 获取对应的标签\n",
    "    \n",
    "#     print(\"样本图像形状:\", sample_image.shape)  # 打印图像形状\n",
    "#     print(\"样本标签:\", sample_label.item())    # 打印标签\n",
    "#     break  # 只需查看第一批数据，使用 break 跳出循环\n",
    "\n",
    "\n",
    "# 创建网络模型\n",
    "tudui = Tudui()\n",
    "\n",
    "# 定义损失函数 用交叉熵\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# 定义优化器 选择的是随机梯度下降\n",
    "# 1e-2 = 1*(10)^(-2) = 1/100 =0.01\n",
    "learning_rate = 1e-2\n",
    "optimizer = torch.optim.SGD(tudui.parameters(),lr=learning_rate)\n",
    "\n",
    "# 设置训练网络的一些参数\n",
    "# 记录训练的次数\n",
    "total_train_step = 0\n",
    "# 记录测试的次数\n",
    "total_test_step = 0\n",
    "# 训练的轮数\n",
    "epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------第1轮训练开始-----------\n",
      "训练次数:100,Loss:2.295762062072754\n",
      "训练次数:200,Loss:2.290508270263672\n",
      "训练次数:300,Loss:2.2823140621185303\n",
      "训练次数:400,Loss:2.2400593757629395\n",
      "训练次数:500,Loss:2.159593105316162\n",
      "训练次数:600,Loss:2.060598134994507\n",
      "训练次数:700,Loss:2.0133888721466064\n",
      "整体测试集上的loss:317.5434265136719\n",
      "------------第0轮测试结束------------\n",
      "模型已保存\n",
      "-----------第2轮训练开始-----------\n",
      "训练次数:800,Loss:1.9282879829406738\n",
      "训练次数:900,Loss:1.8913767337799072\n",
      "训练次数:1000,Loss:1.9943794012069702\n",
      "训练次数:1100,Loss:1.9976814985275269\n",
      "训练次数:1200,Loss:1.7579548358917236\n",
      "训练次数:1300,Loss:1.7011998891830444\n",
      "训练次数:1400,Loss:1.7928193807601929\n",
      "训练次数:1500,Loss:1.8460185527801514\n",
      "整体测试集上的loss:311.77264404296875\n",
      "------------第1轮测试结束------------\n",
      "模型已保存\n",
      "-----------第3轮训练开始-----------\n",
      "训练次数:1600,Loss:1.813776969909668\n",
      "训练次数:1700,Loss:1.65890634059906\n",
      "训练次数:1800,Loss:1.9117518663406372\n",
      "训练次数:1900,Loss:1.7380167245864868\n",
      "训练次数:2000,Loss:1.9327287673950195\n",
      "训练次数:2100,Loss:1.520822286605835\n",
      "训练次数:2200,Loss:1.474498987197876\n",
      "训练次数:2300,Loss:1.7858017683029175\n",
      "整体测试集上的loss:273.05401611328125\n",
      "------------第2轮测试结束------------\n",
      "模型已保存\n",
      "-----------第4轮训练开始-----------\n",
      "训练次数:2400,Loss:1.6895933151245117\n",
      "训练次数:2500,Loss:1.3617310523986816\n",
      "训练次数:2600,Loss:1.6040234565734863\n",
      "训练次数:2700,Loss:1.6652812957763672\n",
      "训练次数:2800,Loss:1.4552545547485352\n",
      "训练次数:2900,Loss:1.5901309251785278\n",
      "训练次数:3000,Loss:1.35044527053833\n",
      "训练次数:3100,Loss:1.5152912139892578\n",
      "整体测试集上的loss:268.4412536621094\n",
      "------------第3轮测试结束------------\n",
      "模型已保存\n",
      "-----------第5轮训练开始-----------\n",
      "训练次数:3200,Loss:1.337996482849121\n",
      "训练次数:3300,Loss:1.4550094604492188\n",
      "训练次数:3400,Loss:1.459428310394287\n",
      "训练次数:3500,Loss:1.5594773292541504\n",
      "训练次数:3600,Loss:1.570430040359497\n",
      "训练次数:3700,Loss:1.3610758781433105\n",
      "训练次数:3800,Loss:1.2890806198120117\n",
      "训练次数:3900,Loss:1.4272323846817017\n",
      "整体测试集上的loss:251.87265014648438\n",
      "------------第4轮测试结束------------\n",
      "模型已保存\n",
      "-----------第6轮训练开始-----------\n",
      "训练次数:4000,Loss:1.3918818235397339\n",
      "训练次数:4100,Loss:1.4394177198410034\n",
      "训练次数:4200,Loss:1.5590145587921143\n",
      "训练次数:4300,Loss:1.1939424276351929\n",
      "训练次数:4400,Loss:1.1088650226593018\n",
      "训练次数:4500,Loss:1.3640633821487427\n",
      "训练次数:4600,Loss:1.399061679840088\n",
      "整体测试集上的loss:240.86866760253906\n",
      "------------第5轮测试结束------------\n",
      "模型已保存\n",
      "-----------第7轮训练开始-----------\n",
      "训练次数:4700,Loss:1.3383880853652954\n",
      "训练次数:4800,Loss:1.5195316076278687\n",
      "训练次数:4900,Loss:1.3556888103485107\n",
      "训练次数:5000,Loss:1.4312328100204468\n",
      "训练次数:5100,Loss:0.9736577272415161\n",
      "训练次数:5200,Loss:1.3652515411376953\n",
      "训练次数:5300,Loss:1.1652034521102905\n",
      "训练次数:5400,Loss:1.3787035942077637\n",
      "整体测试集上的loss:228.70257568359375\n",
      "------------第6轮测试结束------------\n",
      "模型已保存\n",
      "-----------第8轮训练开始-----------\n",
      "训练次数:5500,Loss:1.1997634172439575\n",
      "训练次数:5600,Loss:1.162611961364746\n",
      "训练次数:5700,Loss:1.231740117073059\n",
      "训练次数:5800,Loss:1.2087442874908447\n",
      "训练次数:5900,Loss:1.3577549457550049\n",
      "训练次数:6000,Loss:1.518038034439087\n",
      "训练次数:6100,Loss:1.0477010011672974\n",
      "训练次数:6200,Loss:1.0908910036087036\n",
      "整体测试集上的loss:216.02374267578125\n",
      "------------第7轮测试结束------------\n",
      "模型已保存\n",
      "-----------第9轮训练开始-----------\n",
      "训练次数:6300,Loss:1.3759419918060303\n",
      "训练次数:6400,Loss:1.0835362672805786\n",
      "训练次数:6500,Loss:1.5749006271362305\n",
      "训练次数:6600,Loss:1.120933175086975\n",
      "训练次数:6700,Loss:1.0893977880477905\n",
      "训练次数:6800,Loss:1.1795272827148438\n",
      "训练次数:6900,Loss:1.0837900638580322\n",
      "训练次数:7000,Loss:0.8921842575073242\n",
      "整体测试集上的loss:205.1334686279297\n",
      "------------第8轮测试结束------------\n",
      "模型已保存\n",
      "-----------第10轮训练开始-----------\n",
      "训练次数:7100,Loss:1.2405345439910889\n",
      "训练次数:7200,Loss:0.9391055703163147\n",
      "训练次数:7300,Loss:1.1243003606796265\n",
      "训练次数:7400,Loss:0.8835951685905457\n",
      "训练次数:7500,Loss:1.2176493406295776\n",
      "训练次数:7600,Loss:1.2545533180236816\n",
      "训练次数:7700,Loss:0.9160985350608826\n",
      "训练次数:7800,Loss:1.2374809980392456\n",
      "整体测试集上的loss:198.97015380859375\n",
      "------------第9轮测试结束------------\n",
      "模型已保存\n"
     ]
    }
   ],
   "source": [
    "# 添加tensorboard\n",
    "writer = SummaryWriter(\"../net_logs\")\n",
    "\n",
    "for i in range(epoch):\n",
    "    print(\"-----------第{}轮训练开始-----------\".format(i+1))\n",
    "\n",
    "    # -- 训练步骤开始\n",
    "    for data in train_dataloader:\n",
    "        imgs,targets = data\n",
    "        outputs = tudui(imgs)\n",
    "        loss = loss_fn(outputs,targets)\n",
    "\n",
    "        # 优化器优化模型\n",
    "        # 利用优化器将梯度清零\n",
    "        optimizer.zero_grad()\n",
    "        # 利用反向传播得到每个梯度的结点\n",
    "        loss.backward()\n",
    "        # 调用优化器\n",
    "        optimizer.step()\n",
    "\n",
    "        # 训练次数+1\n",
    "        total_train_step += 1\n",
    "        if total_train_step % 100 == 0:\n",
    "            print(\"训练次数:{},Loss:{}\".format(total_train_step,loss))\n",
    "            writer.add_scalar(\"train_loss\",loss.item(), total_train_step)\n",
    "\n",
    "    # -- 测试步骤开始\n",
    "    # 计算整个数据集上的loss\n",
    "    total_test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_dataloader:\n",
    "            imgs,targets = data\n",
    "            outputs = tudui(imgs)\n",
    "            # 计算数据的损失\n",
    "            loss = loss_fn(outputs,targets)\n",
    "            # 计算整体损失\n",
    "            total_test_loss = total_test_loss + loss\n",
    "    print(\"整体测试集上的loss:{}\".format(total_test_loss))\n",
    "    writer.add_scalar(\"test_loss\",total_test_loss, total_test_step)\n",
    "    total_test_step += 1\n",
    "    print(f\"-----------第{total_test_step}轮测试结束-----------\")\n",
    "    \n",
    "    \n",
    "\n",
    "    # 保存训练时每一轮的模型\n",
    "    torch.save(tudui, \"./model_pth/tudui_{}.pth\".format(i))\n",
    "    print('模型已保存')\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 完整的模型训练套路(二)\n",
    "* 增加优化代码：添加测试数据集正确率\n",
    "* 正确率的计算思路"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假设有一个批次包含 3 个样本，输出和目标如下：<br>\n",
    "\n",
    "输出 (outputs):\n",
    "\n",
    "[[2.0, 1.0, 0.1, 0.2, 0.5, 0.0, 0.3, 0.1, 0.1, 0.4],  # 真实标签为 0 \n",
    "\n",
    " [0.1, 0.4, 2.0, 0.3, 0.1, 0.0, 0.1, 0.2, 0.1, 0.2],  # 真实标签为 2 \n",
    "\n",
    " [0.3, 0.5, 0.1, 1.0, 0.2, 0.0, 0.1, 0.1, 2.0, 0.3]]  # 真实标签为 8 \n",
    "\n",
    "\n",
    "目标 (targets): \n",
    "\n",
    "[0, 2, 8]       \n",
    "<br>\n",
    "在这个例子中，损失函数会：<br>\n",
    "对每行应用 Softmax，计算每个样本的类别概率。<br>\n",
    "取每个样本对应真实标签的概率，应用交叉熵公式计算损失。<br>\n",
    "对所有样本的损失取平均，得到最终的损失值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1])\n",
      "tensor([1, 0])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "outputs = torch.tensor([[0.1, 0.2],\n",
    "                        [0.5, 0.4]])\n",
    "# 0的时候按列比较，1的时候按行比较\n",
    "print(outputs.argmax(0))\n",
    "print(outputs.argmax(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------第1轮训练开始-----------\n",
      "训练次数:100,Loss:2.2818009853363037\n",
      "训练次数:200,Loss:2.272014856338501\n",
      "训练次数:300,Loss:2.1814661026000977\n",
      "训练次数:400,Loss:2.12896990776062\n",
      "训练次数:500,Loss:1.9971290826797485\n",
      "训练次数:600,Loss:2.010012626647949\n",
      "训练次数:700,Loss:1.9645278453826904\n",
      "整体测试集上的loss:307.31292724609375\n",
      "整体测试集上的正确率:0.2976999878883362\n",
      "-----------第1轮测试结束-----------\n",
      "模型已保存\n",
      "-----------第2轮训练开始-----------\n",
      "训练次数:800,Loss:1.8099256753921509\n",
      "训练次数:900,Loss:1.7601419687271118\n",
      "训练次数:1000,Loss:1.9045765399932861\n",
      "训练次数:1100,Loss:1.9873415231704712\n",
      "训练次数:1200,Loss:1.637665033340454\n",
      "训练次数:1300,Loss:1.592820405960083\n",
      "训练次数:1400,Loss:1.6909105777740479\n",
      "训练次数:1500,Loss:1.7544349431991577\n",
      "整体测试集上的loss:292.11785888671875\n",
      "整体测试集上的正确率:0.3384000062942505\n",
      "-----------第2轮测试结束-----------\n",
      "模型已保存\n",
      "-----------第3轮训练开始-----------\n",
      "训练次数:1600,Loss:1.6719130277633667\n",
      "训练次数:1700,Loss:1.625885248184204\n",
      "训练次数:1800,Loss:1.9291118383407593\n",
      "训练次数:1900,Loss:1.6375724077224731\n",
      "训练次数:2000,Loss:1.9054876565933228\n",
      "训练次数:2100,Loss:1.5076005458831787\n",
      "训练次数:2200,Loss:1.4564669132232666\n",
      "训练次数:2300,Loss:1.7600747346878052\n",
      "整体测试集上的loss:257.0141906738281\n",
      "整体测试集上的正确率:0.40869998931884766\n",
      "-----------第3轮测试结束-----------\n",
      "模型已保存\n",
      "-----------第4轮训练开始-----------\n",
      "训练次数:2400,Loss:1.7302075624465942\n",
      "训练次数:2500,Loss:1.3259670734405518\n",
      "训练次数:2600,Loss:1.557713270187378\n",
      "训练次数:2700,Loss:1.670883297920227\n",
      "训练次数:2800,Loss:1.4814612865447998\n",
      "训练次数:2900,Loss:1.5735626220703125\n",
      "训练次数:3000,Loss:1.328511357307434\n",
      "训练次数:3100,Loss:1.5045124292373657\n",
      "整体测试集上的loss:250.7203369140625\n",
      "整体测试集上的正确率:0.42100000381469727\n",
      "-----------第4轮测试结束-----------\n",
      "模型已保存\n",
      "-----------第5轮训练开始-----------\n",
      "训练次数:3200,Loss:1.3218653202056885\n",
      "训练次数:3300,Loss:1.4368419647216797\n",
      "训练次数:3400,Loss:1.4517461061477661\n",
      "训练次数:3500,Loss:1.5264062881469727\n",
      "训练次数:3600,Loss:1.6020618677139282\n",
      "训练次数:3700,Loss:1.3165415525436401\n",
      "训练次数:3800,Loss:1.2383899688720703\n",
      "训练次数:3900,Loss:1.4443321228027344\n",
      "整体测试集上的loss:244.46376037597656\n",
      "整体测试集上的正确率:0.4336000084877014\n",
      "-----------第5轮测试结束-----------\n",
      "模型已保存\n",
      "-----------第6轮训练开始-----------\n",
      "训练次数:4000,Loss:1.4100289344787598\n",
      "训练次数:4100,Loss:1.4499894380569458\n",
      "训练次数:4200,Loss:1.5531415939331055\n",
      "训练次数:4300,Loss:1.2321863174438477\n",
      "训练次数:4400,Loss:1.147643804550171\n",
      "训练次数:4500,Loss:1.315592885017395\n",
      "训练次数:4600,Loss:1.4180517196655273\n",
      "整体测试集上的loss:234.42091369628906\n",
      "整体测试集上的正确率:0.4560000002384186\n",
      "-----------第6轮测试结束-----------\n",
      "模型已保存\n",
      "-----------第7轮训练开始-----------\n",
      "训练次数:4700,Loss:1.2810516357421875\n",
      "训练次数:4800,Loss:1.51768958568573\n",
      "训练次数:4900,Loss:1.3971389532089233\n",
      "训练次数:5000,Loss:1.406421422958374\n",
      "训练次数:5100,Loss:1.035051703453064\n",
      "训练次数:5200,Loss:1.285244345664978\n",
      "训练次数:5300,Loss:1.2562450170516968\n",
      "训练次数:5400,Loss:1.3794331550598145\n",
      "整体测试集上的loss:223.042236328125\n",
      "整体测试集上的正确率:0.4846000075340271\n",
      "-----------第7轮测试结束-----------\n",
      "模型已保存\n",
      "-----------第8轮训练开始-----------\n",
      "训练次数:5500,Loss:1.1544480323791504\n",
      "训练次数:5600,Loss:1.232928991317749\n",
      "训练次数:5700,Loss:1.2592979669570923\n",
      "训练次数:5800,Loss:1.2494367361068726\n",
      "训练次数:5900,Loss:1.3750391006469727\n",
      "训练次数:6000,Loss:1.546885371208191\n",
      "训练次数:6100,Loss:1.088268518447876\n",
      "训练次数:6200,Loss:1.0921183824539185\n",
      "整体测试集上的loss:211.7772216796875\n",
      "整体测试集上的正确率:0.5142999887466431\n",
      "-----------第8轮测试结束-----------\n",
      "模型已保存\n",
      "-----------第9轮训练开始-----------\n",
      "训练次数:6300,Loss:1.3601359128952026\n",
      "训练次数:6400,Loss:1.1621259450912476\n",
      "训练次数:6500,Loss:1.63995361328125\n",
      "训练次数:6600,Loss:1.0990195274353027\n",
      "训练次数:6700,Loss:1.0358846187591553\n",
      "训练次数:6800,Loss:1.161672592163086\n",
      "训练次数:6900,Loss:1.1030272245407104\n",
      "训练次数:7000,Loss:0.9463536143302917\n",
      "整体测试集上的loss:201.82760620117188\n",
      "整体测试集上的正确率:0.5437999963760376\n",
      "-----------第9轮测试结束-----------\n",
      "模型已保存\n",
      "-----------第10轮训练开始-----------\n",
      "训练次数:7100,Loss:1.2356371879577637\n",
      "训练次数:7200,Loss:0.9498627185821533\n",
      "训练次数:7300,Loss:1.0562176704406738\n",
      "训练次数:7400,Loss:0.8695214986801147\n",
      "训练次数:7500,Loss:1.2140603065490723\n",
      "训练次数:7600,Loss:1.2574124336242676\n",
      "训练次数:7700,Loss:0.944267988204956\n",
      "训练次数:7800,Loss:1.2586519718170166\n",
      "整体测试集上的loss:193.82167053222656\n",
      "整体测试集上的正确率:0.5631999969482422\n",
      "-----------第10轮测试结束-----------\n",
      "模型已保存\n"
     ]
    }
   ],
   "source": [
    "# 添加tensorboard\n",
    "writer = SummaryWriter(\"../net_logs\")\n",
    "\n",
    "for i in range(epoch):\n",
    "    print(\"-----------第{}轮训练开始-----------\".format(i+1))\n",
    "\n",
    "    # -- 训练步骤开始\n",
    "    for data in train_dataloader:\n",
    "        imgs,targets = data\n",
    "        outputs = tudui(imgs)\n",
    "        loss = loss_fn(outputs,targets)\n",
    "\n",
    "        # 优化器优化模型\n",
    "        # 利用优化器将梯度清零\n",
    "        optimizer.zero_grad()\n",
    "        # 利用反向传播得到每个梯度的结点\n",
    "        loss.backward()\n",
    "        # 调用优化器\n",
    "        optimizer.step()\n",
    "\n",
    "        # 训练次数+1\n",
    "        total_train_step += 1\n",
    "        if total_train_step % 100 == 0:\n",
    "            print(\"训练次数:{},Loss:{}\".format(total_train_step,loss))\n",
    "            writer.add_scalar(\"train_loss\",loss.item(), total_train_step)\n",
    "\n",
    "    # -- 测试步骤开始\n",
    "    # 计算整个数据集上的loss\n",
    "    total_test_loss = 0\n",
    "    # 计算整体的正确率 整体正确的个数 初始为0\n",
    "    total_true_num = 0\n",
    "    with torch.no_grad():\n",
    "        for data in test_dataloader:\n",
    "            imgs,targets = data\n",
    "            outputs = tudui(imgs)\n",
    "            # 计算数据的损失\n",
    "            loss = loss_fn(outputs,targets)\n",
    "            # 计算整体损失\n",
    "            total_test_loss = total_test_loss + loss\n",
    "\n",
    "            # 计算准确率\n",
    "            batch_true_num = (outputs.argmax(1)==targets).sum()\n",
    "            total_true_num += batch_true_num         \n",
    "    test_accuracy = total_true_num/test_data_size\n",
    "\n",
    "    print(\"整体测试集上的loss:{}\".format(total_test_loss))\n",
    "    print(f\"整体测试集上的正确率:{test_accuracy}\")\n",
    "\n",
    "    writer.add_scalar(\"test_2_loss\",total_test_loss, total_test_step)\n",
    "    writer.add_scalar(\"test_2_accuracy\",test_accuracy,total_test_step)\n",
    "\n",
    "    total_test_step += 1\n",
    "    print(f\"-----------第{total_test_step}轮测试结束-----------\")    \n",
    "\n",
    "\n",
    "    # 保存训练时每一轮的模型\n",
    "    torch.save(tudui, \"./model_pth/tudui_2_{}.pth\".format(i))\n",
    "    print('模型已保存')\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 29. 完整的模型训练套路(三)\n",
    "浅浅修改(tao就不写了), 增加了\n",
    "\n",
    "tudui.train() # 作用:将网络设置成训练模式 只对部分网络层有作用,例如Dropout层,BatchNorm层等\n",
    "\n",
    "tudui.eval() # 设置模型进入验证状态 只对特定层有作用,例如Dropout层,BatchNorm层等"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov5_frog38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
