{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                   Version\n",
      "------------------------- --------------------\n",
      "absl-py                   2.0.0\n",
      "aiofiles                  23.2.1\n",
      "aiohttp                   3.8.6\n",
      "aiosignal                 1.3.1\n",
      "albumentations            0.4.3\n",
      "altair                    5.1.2\n",
      "annotated-types           0.6.0\n",
      "antlr4-python3-runtime    4.8\n",
      "anyio                     3.7.1\n",
      "appdirs                   1.4.4\n",
      "asttokens                 2.4.1\n",
      "async-timeout             4.0.3\n",
      "attrs                     23.1.0\n",
      "backcall                  0.2.0\n",
      "backports.zoneinfo        0.2.1\n",
      "cachetools                5.3.2\n",
      "certifi                   2023.7.22\n",
      "charset-normalizer        3.3.1\n",
      "clean-fid                 0.1.35\n",
      "click                     8.1.7\n",
      "clip-anytorch             2.5.2\n",
      "comm                      0.2.2\n",
      "contourpy                 1.1.1\n",
      "cycler                    0.12.1\n",
      "datasets                  2.8.0\n",
      "dctorch                   0.1.2\n",
      "debugpy                   1.6.7\n",
      "decorator                 5.1.1\n",
      "docker-pycreds            0.4.0\n",
      "einops                    0.3.0\n",
      "entrypoints               0.4\n",
      "exceptiongroup            1.1.3\n",
      "executing                 2.1.0\n",
      "fastapi                   0.104.1\n",
      "ffmpy                     0.3.1\n",
      "filelock                  3.13.1\n",
      "fonttools                 4.44.0\n",
      "frozenlist                1.4.0\n",
      "fsspec                    2023.10.0\n",
      "ftfy                      6.1.1\n",
      "gitdb                     4.0.11\n",
      "GitPython                 3.1.40\n",
      "google-auth               2.23.4\n",
      "google-auth-oauthlib      1.0.0\n",
      "gradio                    4.1.1\n",
      "gradio_client             0.7.0\n",
      "grpcio                    1.59.0\n",
      "h11                       0.14.0\n",
      "httpcore                  1.0.1\n",
      "httpx                     0.25.1\n",
      "idna                      3.4\n",
      "imageio-ffmpeg            0.4.2\n",
      "imgviz                    1.7.5\n",
      "importlib-metadata        6.8.0\n",
      "importlib-resources       6.1.0\n",
      "invisible-watermark       0.2.0\n",
      "ipykernel                 6.29.5\n",
      "ipython                   8.12.0\n",
      "jedi                      0.18.2\n",
      "joblib                    1.3.2\n",
      "jsonmerge                 1.9.2\n",
      "jsonpatch                 1.33\n",
      "jsonpointer               2.4\n",
      "jsonschema                4.19.2\n",
      "jsonschema-specifications 2023.7.1\n",
      "jupyter-client            7.3.4\n",
      "jupyter_core              5.7.2\n",
      "kiwisolver                1.4.5\n",
      "kornia                    0.6.0\n",
      "lazy_loader               0.3\n",
      "Markdown                  3.5.1\n",
      "markdown-it-py            3.0.0\n",
      "MarkupSafe                2.1.3\n",
      "matplotlib                3.7.5\n",
      "matplotlib-inline         0.1.7\n",
      "mdurl                     0.1.1\n",
      "mpmath                    1.3.0\n",
      "multidict                 6.0.4\n",
      "nest_asyncio              1.6.0\n",
      "networkx                  3.1\n",
      "numpy                     1.24.4\n",
      "nvidia-cublas-cu12        12.1.3.1\n",
      "nvidia-cuda-cupti-cu12    12.1.105\n",
      "nvidia-cuda-nvrtc-cu12    12.1.105\n",
      "nvidia-cuda-runtime-cu12  12.1.105\n",
      "nvidia-cufft-cu12         11.0.2.54\n",
      "nvidia-curand-cu12        10.3.2.106\n",
      "nvidia-cusolver-cu12      11.4.5.107\n",
      "nvidia-cusparse-cu12      12.1.0.106\n",
      "nvidia-nvjitlink-cu12     12.3.52\n",
      "nvidia-nvtx-cu12          12.1.105\n",
      "oauthlib                  3.2.2\n",
      "omegaconf                 2.1.1\n",
      "onnx                      1.15.0\n",
      "openai                    0.28.1\n",
      "opencv-python             4.8.1.78\n",
      "opencv-python-headless    4.8.1.78\n",
      "orjson                    3.9.10\n",
      "packaging                 23.2\n",
      "pandas                    1.2.4\n",
      "parso                     0.8.4\n",
      "pathtools                 0.1.2\n",
      "pexpect                   4.9.0\n",
      "pickleshare               0.7.5\n",
      "Pillow                    9.5.0\n",
      "pip                       23.3\n",
      "pkgutil_resolve_name      1.3.10\n",
      "platformdirs              4.3.6\n",
      "prompt_toolkit            3.0.48\n",
      "protobuf                  4.24.4\n",
      "psutil                    5.9.6\n",
      "ptyprocess                0.7.0\n",
      "pudb                      2019.2\n",
      "pure_eval                 0.2.3\n",
      "pyarrow                   14.0.0\n",
      "pyasn1                    0.5.0\n",
      "pyasn1-modules            0.3.0\n",
      "pycocotools               2.0.7\n",
      "pydantic                  2.4.2\n",
      "pydantic_core             2.10.1\n",
      "pydeck                    0.8.1b0\n",
      "pyDeprecate               0.3.1\n",
      "pydub                     0.25.1\n",
      "Pygments                  2.16.1\n",
      "pyparsing                 3.1.1\n",
      "python-dateutil           2.8.2\n",
      "python-multipart          0.0.6\n",
      "pytorch-lightning         1.4.2\n",
      "pytz                      2023.3.post1\n",
      "PyWavelets                1.4.1\n",
      "PyYAML                    6.0.1\n",
      "pyzmq                     25.1.2\n",
      "referencing               0.30.2\n",
      "regex                     2023.10.3\n",
      "requests                  2.31.0\n",
      "requests-oauthlib         1.3.1\n",
      "responses                 0.18.0\n",
      "rich                      13.6.0\n",
      "rpds-py                   0.12.0\n",
      "rsa                       4.8\n",
      "scikit-learn              0.24.2\n",
      "scipy                     1.5.1\n",
      "seaborn                   0.13.0\n",
      "semantic-version          2.10.0\n",
      "sentry-sdk                1.34.0\n",
      "setproctitle              1.3.3\n",
      "setuptools                68.0.0\n",
      "shellingham               1.5.4\n",
      "six                       1.16.0\n",
      "smmap                     5.0.1\n",
      "sniffio                   1.3.0\n",
      "some-package              0.1\n",
      "stack-data                0.6.2\n",
      "starlette                 0.27.0\n",
      "streamlit                 1.28.1\n",
      "sympy                     1.12\n",
      "tenacity                  8.2.3\n",
      "tensorboard               2.14.0\n",
      "tensorboard-data-server   0.7.2\n",
      "test-tube                 0.7.5\n",
      "thop                      0.1.1.post2209072238\n",
      "threadpoolctl             3.2.0\n",
      "tifffile                  2023.7.10\n",
      "tokenizers                0.12.1\n",
      "toml                      0.10.2\n",
      "tomlkit                   0.12.0\n",
      "toolz                     0.12.0\n",
      "torch                     1.13.1+cu117\n",
      "torch-fidelity            0.3.0\n",
      "torchaudio                0.13.1+cu117\n",
      "torchdiffeq               0.2.3\n",
      "torchfile                 0.1.0\n",
      "torchmetrics              0.6.0\n",
      "torchsde                  0.2.6\n",
      "torchvision               0.14.1+cu117\n",
      "tornado                   6.3.3\n",
      "tqdm                      4.66.1\n",
      "traitlets                 5.14.3\n",
      "trampoline                0.1.2\n",
      "transformers              4.27.0\n",
      "typer                     0.9.0\n",
      "typing_extensions         4.8.0\n",
      "tzdata                    2023.3\n",
      "tzlocal                   5.2\n",
      "urllib3                   2.0.7\n",
      "urwid                     2.2.3\n",
      "uvicorn                   0.24.0\n",
      "validators                0.22.0\n",
      "visdom                    0.1.8.9\n",
      "wandb                     0.15.12\n",
      "watchdog                  3.0.0\n",
      "wcwidth                   0.2.9\n",
      "websocket-client          1.7.0\n",
      "websockets                11.0.3\n",
      "Werkzeug                  3.0.1\n",
      "wheel                     0.41.2\n",
      "xxhash                    3.4.1\n",
      "yarl                      1.9.2\n",
      "zipp                      3.17.0\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kunyue/.local/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class SummaryWriter in module torch.utils.tensorboard.writer:\n",
      "\n",
      "class SummaryWriter(builtins.object)\n",
      " |  SummaryWriter(log_dir=None, comment='', purge_step=None, max_queue=10, flush_secs=120, filename_suffix='')\n",
      " |  \n",
      " |  Writes entries directly to event files in the log_dir to be\n",
      " |  consumed by TensorBoard.\n",
      " |  \n",
      " |  The `SummaryWriter` class provides a high-level API to create an event file\n",
      " |  in a given directory and add summaries and events to it. The class updates the\n",
      " |  file contents asynchronously. This allows a training program to call methods\n",
      " |  to add data to the file directly from the training loop, without slowing down\n",
      " |  training.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __enter__(self)\n",
      " |  \n",
      " |  __exit__(self, exc_type, exc_val, exc_tb)\n",
      " |  \n",
      " |  __init__(self, log_dir=None, comment='', purge_step=None, max_queue=10, flush_secs=120, filename_suffix='')\n",
      " |      Creates a `SummaryWriter` that will write out events and summaries\n",
      " |      to the event file.\n",
      " |      \n",
      " |      Args:\n",
      " |          log_dir (str): Save directory location. Default is\n",
      " |            runs/**CURRENT_DATETIME_HOSTNAME**, which changes after each run.\n",
      " |            Use hierarchical folder structure to compare\n",
      " |            between runs easily. e.g. pass in 'runs/exp1', 'runs/exp2', etc.\n",
      " |            for each new experiment to compare across them.\n",
      " |          comment (str): Comment log_dir suffix appended to the default\n",
      " |            ``log_dir``. If ``log_dir`` is assigned, this argument has no effect.\n",
      " |          purge_step (int):\n",
      " |            When logging crashes at step :math:`T+X` and restarts at step :math:`T`,\n",
      " |            any events whose global_step larger or equal to :math:`T` will be\n",
      " |            purged and hidden from TensorBoard.\n",
      " |            Note that crashed and resumed experiments should have the same ``log_dir``.\n",
      " |          max_queue (int): Size of the queue for pending events and\n",
      " |            summaries before one of the 'add' calls forces a flush to disk.\n",
      " |            Default is ten items.\n",
      " |          flush_secs (int): How often, in seconds, to flush the\n",
      " |            pending events and summaries to disk. Default is every two minutes.\n",
      " |          filename_suffix (str): Suffix added to all event filenames in\n",
      " |            the log_dir directory. More details on filename construction in\n",
      " |            tensorboard.summary.writer.event_file_writer.EventFileWriter.\n",
      " |      \n",
      " |      Examples::\n",
      " |      \n",
      " |          from torch.utils.tensorboard import SummaryWriter\n",
      " |      \n",
      " |          # create a summary writer with automatically generated folder name.\n",
      " |          writer = SummaryWriter()\n",
      " |          # folder location: runs/May04_22-14-54_s-MacBook-Pro.local/\n",
      " |      \n",
      " |          # create a summary writer using the specified folder name.\n",
      " |          writer = SummaryWriter(\"my_experiment\")\n",
      " |          # folder location: my_experiment\n",
      " |      \n",
      " |          # create a summary writer with comment appended.\n",
      " |          writer = SummaryWriter(comment=\"LR_0.1_BATCH_16\")\n",
      " |          # folder location: runs/May04_22-14-54_s-MacBook-Pro.localLR_0.1_BATCH_16/\n",
      " |  \n",
      " |  add_audio(self, tag, snd_tensor, global_step=None, sample_rate=44100, walltime=None)\n",
      " |      Add audio data to summary.\n",
      " |      \n",
      " |      Args:\n",
      " |          tag (str): Data identifier\n",
      " |          snd_tensor (torch.Tensor): Sound data\n",
      " |          global_step (int): Global step value to record\n",
      " |          sample_rate (int): sample rate in Hz\n",
      " |          walltime (float): Optional override default walltime (time.time())\n",
      " |            seconds after epoch of event\n",
      " |      Shape:\n",
      " |          snd_tensor: :math:`(1, L)`. The values should lie between [-1, 1].\n",
      " |  \n",
      " |  add_custom_scalars(self, layout)\n",
      " |      Create special chart by collecting charts tags in 'scalars'. Note that this function can only be called once\n",
      " |      for each SummaryWriter() object. Because it only provides metadata to tensorboard, the function can be called\n",
      " |      before or after the training loop.\n",
      " |      \n",
      " |      Args:\n",
      " |          layout (dict): {categoryName: *charts*}, where *charts* is also a dictionary\n",
      " |            {chartName: *ListOfProperties*}. The first element in *ListOfProperties* is the chart's type\n",
      " |            (one of **Multiline** or **Margin**) and the second element should be a list containing the tags\n",
      " |            you have used in add_scalar function, which will be collected into the new chart.\n",
      " |      \n",
      " |      Examples::\n",
      " |      \n",
      " |          layout = {'Taiwan':{'twse':['Multiline',['twse/0050', 'twse/2330']]},\n",
      " |                       'USA':{ 'dow':['Margin',   ['dow/aaa', 'dow/bbb', 'dow/ccc']],\n",
      " |                            'nasdaq':['Margin',   ['nasdaq/aaa', 'nasdaq/bbb', 'nasdaq/ccc']]}}\n",
      " |      \n",
      " |          writer.add_custom_scalars(layout)\n",
      " |  \n",
      " |  add_custom_scalars_marginchart(self, tags, category='default', title='untitled')\n",
      " |      Shorthand for creating marginchart. Similar to ``add_custom_scalars()``, but the only necessary argument\n",
      " |      is *tags*, which should have exactly 3 elements.\n",
      " |      \n",
      " |      Args:\n",
      " |          tags (list): list of tags that have been used in ``add_scalar()``\n",
      " |      \n",
      " |      Examples::\n",
      " |      \n",
      " |          writer.add_custom_scalars_marginchart(['twse/0050', 'twse/2330', 'twse/2006'])\n",
      " |  \n",
      " |  add_custom_scalars_multilinechart(self, tags, category='default', title='untitled')\n",
      " |      Shorthand for creating multilinechart. Similar to ``add_custom_scalars()``, but the only necessary argument\n",
      " |      is *tags*.\n",
      " |      \n",
      " |      Args:\n",
      " |          tags (list): list of tags that have been used in ``add_scalar()``\n",
      " |      \n",
      " |      Examples::\n",
      " |      \n",
      " |          writer.add_custom_scalars_multilinechart(['twse/0050', 'twse/2330'])\n",
      " |  \n",
      " |  add_embedding(self, mat, metadata=None, label_img=None, global_step=None, tag='default', metadata_header=None)\n",
      " |      Add embedding projector data to summary.\n",
      " |      \n",
      " |      Args:\n",
      " |          mat (torch.Tensor or numpy.ndarray): A matrix which each row is the feature vector of the data point\n",
      " |          metadata (list): A list of labels, each element will be convert to string\n",
      " |          label_img (torch.Tensor): Images correspond to each data point\n",
      " |          global_step (int): Global step value to record\n",
      " |          tag (str): Name for the embedding\n",
      " |      Shape:\n",
      " |          mat: :math:`(N, D)`, where N is number of data and D is feature dimension\n",
      " |      \n",
      " |          label_img: :math:`(N, C, H, W)`\n",
      " |      \n",
      " |      Examples::\n",
      " |      \n",
      " |          import keyword\n",
      " |          import torch\n",
      " |          meta = []\n",
      " |          while len(meta)<100:\n",
      " |              meta = meta+keyword.kwlist # get some strings\n",
      " |          meta = meta[:100]\n",
      " |      \n",
      " |          for i, v in enumerate(meta):\n",
      " |              meta[i] = v+str(i)\n",
      " |      \n",
      " |          label_img = torch.rand(100, 3, 10, 32)\n",
      " |          for i in range(100):\n",
      " |              label_img[i]*=i/100.0\n",
      " |      \n",
      " |          writer.add_embedding(torch.randn(100, 5), metadata=meta, label_img=label_img)\n",
      " |          writer.add_embedding(torch.randn(100, 5), label_img=label_img)\n",
      " |          writer.add_embedding(torch.randn(100, 5), metadata=meta)\n",
      " |  \n",
      " |  add_figure(self, tag, figure, global_step=None, close=True, walltime=None)\n",
      " |      Render matplotlib figure into an image and add it to summary.\n",
      " |      \n",
      " |      Note that this requires the ``matplotlib`` package.\n",
      " |      \n",
      " |      Args:\n",
      " |          tag (str): Data identifier\n",
      " |          figure (matplotlib.pyplot.figure) or list of figures: Figure or a list of figures\n",
      " |          global_step (int): Global step value to record\n",
      " |          close (bool): Flag to automatically close the figure\n",
      " |          walltime (float): Optional override default walltime (time.time())\n",
      " |            seconds after epoch of event\n",
      " |  \n",
      " |  add_graph(self, model, input_to_model=None, verbose=False, use_strict_trace=True)\n",
      " |      Add graph data to summary.\n",
      " |      \n",
      " |      Args:\n",
      " |          model (torch.nn.Module): Model to draw.\n",
      " |          input_to_model (torch.Tensor or list of torch.Tensor): A variable or a tuple of\n",
      " |              variables to be fed.\n",
      " |          verbose (bool): Whether to print graph structure in console.\n",
      " |          use_strict_trace (bool): Whether to pass keyword argument `strict` to\n",
      " |              `torch.jit.trace`. Pass False when you want the tracer to\n",
      " |              record your mutable container types (list, dict)\n",
      " |  \n",
      " |  add_histogram(self, tag, values, global_step=None, bins='tensorflow', walltime=None, max_bins=None)\n",
      " |      Add histogram to summary.\n",
      " |      \n",
      " |      Args:\n",
      " |          tag (str): Data identifier\n",
      " |          values (torch.Tensor, numpy.ndarray, or string/blobname): Values to build histogram\n",
      " |          global_step (int): Global step value to record\n",
      " |          bins (str): One of {'tensorflow','auto', 'fd', ...}. This determines how the bins are made. You can find\n",
      " |            other options in: https://docs.scipy.org/doc/numpy/reference/generated/numpy.histogram.html\n",
      " |          walltime (float): Optional override default walltime (time.time())\n",
      " |            seconds after epoch of event\n",
      " |      \n",
      " |      Examples::\n",
      " |      \n",
      " |          from torch.utils.tensorboard import SummaryWriter\n",
      " |          import numpy as np\n",
      " |          writer = SummaryWriter()\n",
      " |          for i in range(10):\n",
      " |              x = np.random.random(1000)\n",
      " |              writer.add_histogram('distribution centers', x + i, i)\n",
      " |          writer.close()\n",
      " |      \n",
      " |      Expected result:\n",
      " |      \n",
      " |      .. image:: _static/img/tensorboard/add_histogram.png\n",
      " |         :scale: 50 %\n",
      " |  \n",
      " |  add_histogram_raw(self, tag, min, max, num, sum, sum_squares, bucket_limits, bucket_counts, global_step=None, walltime=None)\n",
      " |      Adds histogram with raw data.\n",
      " |      \n",
      " |      Args:\n",
      " |          tag (str): Data identifier\n",
      " |          min (float or int): Min value\n",
      " |          max (float or int): Max value\n",
      " |          num (int): Number of values\n",
      " |          sum (float or int): Sum of all values\n",
      " |          sum_squares (float or int): Sum of squares for all values\n",
      " |          bucket_limits (torch.Tensor, numpy.ndarray): Upper value per bucket.\n",
      " |            The number of elements of it should be the same as `bucket_counts`.\n",
      " |          bucket_counts (torch.Tensor, numpy.ndarray): Number of values per bucket\n",
      " |          global_step (int): Global step value to record\n",
      " |          walltime (float): Optional override default walltime (time.time())\n",
      " |            seconds after epoch of event\n",
      " |          see: https://github.com/tensorflow/tensorboard/blob/master/tensorboard/plugins/histogram/README.md\n",
      " |      \n",
      " |      Examples::\n",
      " |      \n",
      " |          from torch.utils.tensorboard import SummaryWriter\n",
      " |          import numpy as np\n",
      " |          writer = SummaryWriter()\n",
      " |          dummy_data = []\n",
      " |          for idx, value in enumerate(range(50)):\n",
      " |              dummy_data += [idx + 0.001] * value\n",
      " |      \n",
      " |          bins = list(range(50+2))\n",
      " |          bins = np.array(bins)\n",
      " |          values = np.array(dummy_data).astype(float).reshape(-1)\n",
      " |          counts, limits = np.histogram(values, bins=bins)\n",
      " |          sum_sq = values.dot(values)\n",
      " |          writer.add_histogram_raw(\n",
      " |              tag='histogram_with_raw_data',\n",
      " |              min=values.min(),\n",
      " |              max=values.max(),\n",
      " |              num=len(values),\n",
      " |              sum=values.sum(),\n",
      " |              sum_squares=sum_sq,\n",
      " |              bucket_limits=limits[1:].tolist(),\n",
      " |              bucket_counts=counts.tolist(),\n",
      " |              global_step=0)\n",
      " |          writer.close()\n",
      " |      \n",
      " |      Expected result:\n",
      " |      \n",
      " |      .. image:: _static/img/tensorboard/add_histogram_raw.png\n",
      " |         :scale: 50 %\n",
      " |  \n",
      " |  add_hparams(self, hparam_dict, metric_dict, hparam_domain_discrete=None, run_name=None)\n",
      " |      Add a set of hyperparameters to be compared in TensorBoard.\n",
      " |      \n",
      " |      Args:\n",
      " |          hparam_dict (dict): Each key-value pair in the dictionary is the\n",
      " |            name of the hyper parameter and it's corresponding value.\n",
      " |            The type of the value can be one of `bool`, `string`, `float`,\n",
      " |            `int`, or `None`.\n",
      " |          metric_dict (dict): Each key-value pair in the dictionary is the\n",
      " |            name of the metric and it's corresponding value. Note that the key used\n",
      " |            here should be unique in the tensorboard record. Otherwise the value\n",
      " |            you added by ``add_scalar`` will be displayed in hparam plugin. In most\n",
      " |            cases, this is unwanted.\n",
      " |          hparam_domain_discrete: (Optional[Dict[str, List[Any]]]) A dictionary that\n",
      " |            contains names of the hyperparameters and all discrete values they can hold\n",
      " |          run_name (str): Name of the run, to be included as part of the logdir.\n",
      " |            If unspecified, will use current timestamp.\n",
      " |      \n",
      " |      Examples::\n",
      " |      \n",
      " |          from torch.utils.tensorboard import SummaryWriter\n",
      " |          with SummaryWriter() as w:\n",
      " |              for i in range(5):\n",
      " |                  w.add_hparams({'lr': 0.1*i, 'bsize': i},\n",
      " |                                {'hparam/accuracy': 10*i, 'hparam/loss': 10*i})\n",
      " |      \n",
      " |      Expected result:\n",
      " |      \n",
      " |      .. image:: _static/img/tensorboard/add_hparam.png\n",
      " |         :scale: 50 %\n",
      " |  \n",
      " |  add_image(self, tag, img_tensor, global_step=None, walltime=None, dataformats='CHW')\n",
      " |      Add image data to summary.\n",
      " |      \n",
      " |      Note that this requires the ``pillow`` package.\n",
      " |      \n",
      " |      Args:\n",
      " |          tag (str): Data identifier\n",
      " |          img_tensor (torch.Tensor, numpy.ndarray, or string/blobname): Image data\n",
      " |          global_step (int): Global step value to record\n",
      " |          walltime (float): Optional override default walltime (time.time())\n",
      " |            seconds after epoch of event\n",
      " |          dataformats (str): Image data format specification of the form\n",
      " |            CHW, HWC, HW, WH, etc.\n",
      " |      Shape:\n",
      " |          img_tensor: Default is :math:`(3, H, W)`. You can use ``torchvision.utils.make_grid()`` to\n",
      " |          convert a batch of tensor into 3xHxW format or call ``add_images`` and let us do the job.\n",
      " |          Tensor with :math:`(1, H, W)`, :math:`(H, W)`, :math:`(H, W, 3)` is also suitable as long as\n",
      " |          corresponding ``dataformats`` argument is passed, e.g. ``CHW``, ``HWC``, ``HW``.\n",
      " |      \n",
      " |      Examples::\n",
      " |      \n",
      " |          from torch.utils.tensorboard import SummaryWriter\n",
      " |          import numpy as np\n",
      " |          img = np.zeros((3, 100, 100))\n",
      " |          img[0] = np.arange(0, 10000).reshape(100, 100) / 10000\n",
      " |          img[1] = 1 - np.arange(0, 10000).reshape(100, 100) / 10000\n",
      " |      \n",
      " |          img_HWC = np.zeros((100, 100, 3))\n",
      " |          img_HWC[:, :, 0] = np.arange(0, 10000).reshape(100, 100) / 10000\n",
      " |          img_HWC[:, :, 1] = 1 - np.arange(0, 10000).reshape(100, 100) / 10000\n",
      " |      \n",
      " |          writer = SummaryWriter()\n",
      " |          writer.add_image('my_image', img, 0)\n",
      " |      \n",
      " |          # If you have non-default dimension setting, set the dataformats argument.\n",
      " |          writer.add_image('my_image_HWC', img_HWC, 0, dataformats='HWC')\n",
      " |          writer.close()\n",
      " |      \n",
      " |      Expected result:\n",
      " |      \n",
      " |      .. image:: _static/img/tensorboard/add_image.png\n",
      " |         :scale: 50 %\n",
      " |  \n",
      " |  add_image_with_boxes(self, tag, img_tensor, box_tensor, global_step=None, walltime=None, rescale=1, dataformats='CHW', labels=None)\n",
      " |      Add image and draw bounding boxes on the image.\n",
      " |      \n",
      " |      Args:\n",
      " |          tag (str): Data identifier\n",
      " |          img_tensor (torch.Tensor, numpy.ndarray, or string/blobname): Image data\n",
      " |          box_tensor (torch.Tensor, numpy.ndarray, or string/blobname): Box data (for detected objects)\n",
      " |            box should be represented as [x1, y1, x2, y2].\n",
      " |          global_step (int): Global step value to record\n",
      " |          walltime (float): Optional override default walltime (time.time())\n",
      " |            seconds after epoch of event\n",
      " |          rescale (float): Optional scale override\n",
      " |          dataformats (str): Image data format specification of the form\n",
      " |            NCHW, NHWC, CHW, HWC, HW, WH, etc.\n",
      " |          labels (list of string): The label to be shown for each bounding box.\n",
      " |      Shape:\n",
      " |          img_tensor: Default is :math:`(3, H, W)`. It can be specified with ``dataformats`` argument.\n",
      " |          e.g. CHW or HWC\n",
      " |      \n",
      " |          box_tensor: (torch.Tensor, numpy.ndarray, or string/blobname): NX4,  where N is the number of\n",
      " |          boxes and each 4 elements in a row represents (xmin, ymin, xmax, ymax).\n",
      " |  \n",
      " |  add_images(self, tag, img_tensor, global_step=None, walltime=None, dataformats='NCHW')\n",
      " |      Add batched image data to summary.\n",
      " |      \n",
      " |      Note that this requires the ``pillow`` package.\n",
      " |      \n",
      " |      Args:\n",
      " |          tag (str): Data identifier\n",
      " |          img_tensor (torch.Tensor, numpy.ndarray, or string/blobname): Image data\n",
      " |          global_step (int): Global step value to record\n",
      " |          walltime (float): Optional override default walltime (time.time())\n",
      " |            seconds after epoch of event\n",
      " |          dataformats (str): Image data format specification of the form\n",
      " |            NCHW, NHWC, CHW, HWC, HW, WH, etc.\n",
      " |      Shape:\n",
      " |          img_tensor: Default is :math:`(N, 3, H, W)`. If ``dataformats`` is specified, other shape will be\n",
      " |          accepted. e.g. NCHW or NHWC.\n",
      " |      \n",
      " |      Examples::\n",
      " |      \n",
      " |          from torch.utils.tensorboard import SummaryWriter\n",
      " |          import numpy as np\n",
      " |      \n",
      " |          img_batch = np.zeros((16, 3, 100, 100))\n",
      " |          for i in range(16):\n",
      " |              img_batch[i, 0] = np.arange(0, 10000).reshape(100, 100) / 10000 / 16 * i\n",
      " |              img_batch[i, 1] = (1 - np.arange(0, 10000).reshape(100, 100) / 10000) / 16 * i\n",
      " |      \n",
      " |          writer = SummaryWriter()\n",
      " |          writer.add_images('my_image_batch', img_batch, 0)\n",
      " |          writer.close()\n",
      " |      \n",
      " |      Expected result:\n",
      " |      \n",
      " |      .. image:: _static/img/tensorboard/add_images.png\n",
      " |         :scale: 30 %\n",
      " |  \n",
      " |  add_mesh(self, tag, vertices, colors=None, faces=None, config_dict=None, global_step=None, walltime=None)\n",
      " |      Add meshes or 3D point clouds to TensorBoard. The visualization is based on Three.js,\n",
      " |      so it allows users to interact with the rendered object. Besides the basic definitions\n",
      " |      such as vertices, faces, users can further provide camera parameter, lighting condition, etc.\n",
      " |      Please check https://threejs.org/docs/index.html#manual/en/introduction/Creating-a-scene for\n",
      " |      advanced usage.\n",
      " |      \n",
      " |      Args:\n",
      " |          tag (str): Data identifier\n",
      " |          vertices (torch.Tensor): List of the 3D coordinates of vertices.\n",
      " |          colors (torch.Tensor): Colors for each vertex\n",
      " |          faces (torch.Tensor): Indices of vertices within each triangle. (Optional)\n",
      " |          config_dict: Dictionary with ThreeJS classes names and configuration.\n",
      " |          global_step (int): Global step value to record\n",
      " |          walltime (float): Optional override default walltime (time.time())\n",
      " |            seconds after epoch of event\n",
      " |      \n",
      " |      Shape:\n",
      " |          vertices: :math:`(B, N, 3)`. (batch, number_of_vertices, channels)\n",
      " |      \n",
      " |          colors: :math:`(B, N, 3)`. The values should lie in [0, 255] for type `uint8` or [0, 1] for type `float`.\n",
      " |      \n",
      " |          faces: :math:`(B, N, 3)`. The values should lie in [0, number_of_vertices] for type `uint8`.\n",
      " |      \n",
      " |      Examples::\n",
      " |      \n",
      " |          from torch.utils.tensorboard import SummaryWriter\n",
      " |          vertices_tensor = torch.as_tensor([\n",
      " |              [1, 1, 1],\n",
      " |              [-1, -1, 1],\n",
      " |              [1, -1, -1],\n",
      " |              [-1, 1, -1],\n",
      " |          ], dtype=torch.float).unsqueeze(0)\n",
      " |          colors_tensor = torch.as_tensor([\n",
      " |              [255, 0, 0],\n",
      " |              [0, 255, 0],\n",
      " |              [0, 0, 255],\n",
      " |              [255, 0, 255],\n",
      " |          ], dtype=torch.int).unsqueeze(0)\n",
      " |          faces_tensor = torch.as_tensor([\n",
      " |              [0, 2, 3],\n",
      " |              [0, 3, 1],\n",
      " |              [0, 1, 2],\n",
      " |              [1, 3, 2],\n",
      " |          ], dtype=torch.int).unsqueeze(0)\n",
      " |      \n",
      " |          writer = SummaryWriter()\n",
      " |          writer.add_mesh('my_mesh', vertices=vertices_tensor, colors=colors_tensor, faces=faces_tensor)\n",
      " |      \n",
      " |          writer.close()\n",
      " |  \n",
      " |  add_onnx_graph(self, prototxt)\n",
      " |  \n",
      " |  add_pr_curve(self, tag, labels, predictions, global_step=None, num_thresholds=127, weights=None, walltime=None)\n",
      " |      Adds precision recall curve.\n",
      " |      Plotting a precision-recall curve lets you understand your model's\n",
      " |      performance under different threshold settings. With this function,\n",
      " |      you provide the ground truth labeling (T/F) and prediction confidence\n",
      " |      (usually the output of your model) for each target. The TensorBoard UI\n",
      " |      will let you choose the threshold interactively.\n",
      " |      \n",
      " |      Args:\n",
      " |          tag (str): Data identifier\n",
      " |          labels (torch.Tensor, numpy.ndarray, or string/blobname):\n",
      " |            Ground truth data. Binary label for each element.\n",
      " |          predictions (torch.Tensor, numpy.ndarray, or string/blobname):\n",
      " |            The probability that an element be classified as true.\n",
      " |            Value should be in [0, 1]\n",
      " |          global_step (int): Global step value to record\n",
      " |          num_thresholds (int): Number of thresholds used to draw the curve.\n",
      " |          walltime (float): Optional override default walltime (time.time())\n",
      " |            seconds after epoch of event\n",
      " |      \n",
      " |      Examples::\n",
      " |      \n",
      " |          from torch.utils.tensorboard import SummaryWriter\n",
      " |          import numpy as np\n",
      " |          labels = np.random.randint(2, size=100)  # binary label\n",
      " |          predictions = np.random.rand(100)\n",
      " |          writer = SummaryWriter()\n",
      " |          writer.add_pr_curve('pr_curve', labels, predictions, 0)\n",
      " |          writer.close()\n",
      " |  \n",
      " |  add_pr_curve_raw(self, tag, true_positive_counts, false_positive_counts, true_negative_counts, false_negative_counts, precision, recall, global_step=None, num_thresholds=127, weights=None, walltime=None)\n",
      " |      Adds precision recall curve with raw data.\n",
      " |      \n",
      " |      Args:\n",
      " |          tag (str): Data identifier\n",
      " |          true_positive_counts (torch.Tensor, numpy.ndarray, or string/blobname): true positive counts\n",
      " |          false_positive_counts (torch.Tensor, numpy.ndarray, or string/blobname): false positive counts\n",
      " |          true_negative_counts (torch.Tensor, numpy.ndarray, or string/blobname): true negative counts\n",
      " |          false_negative_counts (torch.Tensor, numpy.ndarray, or string/blobname): false negative counts\n",
      " |          precision (torch.Tensor, numpy.ndarray, or string/blobname): precision\n",
      " |          recall (torch.Tensor, numpy.ndarray, or string/blobname): recall\n",
      " |          global_step (int): Global step value to record\n",
      " |          num_thresholds (int): Number of thresholds used to draw the curve.\n",
      " |          walltime (float): Optional override default walltime (time.time())\n",
      " |            seconds after epoch of event\n",
      " |          see: https://github.com/tensorflow/tensorboard/blob/master/tensorboard/plugins/pr_curve/README.md\n",
      " |  \n",
      " |  add_scalar(self, tag, scalar_value, global_step=None, walltime=None, new_style=False, double_precision=False)\n",
      " |      Add scalar data to summary.\n",
      " |      \n",
      " |      Args:\n",
      " |          tag (str): Data identifier\n",
      " |          scalar_value (float or string/blobname): Value to save\n",
      " |          global_step (int): Global step value to record\n",
      " |          walltime (float): Optional override default walltime (time.time())\n",
      " |            with seconds after epoch of event\n",
      " |          new_style (boolean): Whether to use new style (tensor field) or old\n",
      " |            style (simple_value field). New style could lead to faster data loading.\n",
      " |      Examples::\n",
      " |      \n",
      " |          from torch.utils.tensorboard import SummaryWriter\n",
      " |          writer = SummaryWriter()\n",
      " |          x = range(100)\n",
      " |          for i in x:\n",
      " |              writer.add_scalar('y=2x', i * 2, i)\n",
      " |          writer.close()\n",
      " |      \n",
      " |      Expected result:\n",
      " |      \n",
      " |      .. image:: _static/img/tensorboard/add_scalar.png\n",
      " |         :scale: 50 %\n",
      " |  \n",
      " |  add_scalars(self, main_tag, tag_scalar_dict, global_step=None, walltime=None)\n",
      " |      Adds many scalar data to summary.\n",
      " |      \n",
      " |      Args:\n",
      " |          main_tag (str): The parent name for the tags\n",
      " |          tag_scalar_dict (dict): Key-value pair storing the tag and corresponding values\n",
      " |          global_step (int): Global step value to record\n",
      " |          walltime (float): Optional override default walltime (time.time())\n",
      " |            seconds after epoch of event\n",
      " |      \n",
      " |      Examples::\n",
      " |      \n",
      " |          from torch.utils.tensorboard import SummaryWriter\n",
      " |          writer = SummaryWriter()\n",
      " |          r = 5\n",
      " |          for i in range(100):\n",
      " |              writer.add_scalars('run_14h', {'xsinx':i*np.sin(i/r),\n",
      " |                                              'xcosx':i*np.cos(i/r),\n",
      " |                                              'tanx': np.tan(i/r)}, i)\n",
      " |          writer.close()\n",
      " |          # This call adds three values to the same scalar plot with the tag\n",
      " |          # 'run_14h' in TensorBoard's scalar section.\n",
      " |      \n",
      " |      Expected result:\n",
      " |      \n",
      " |      .. image:: _static/img/tensorboard/add_scalars.png\n",
      " |         :scale: 50 %\n",
      " |  \n",
      " |  add_text(self, tag, text_string, global_step=None, walltime=None)\n",
      " |      Add text data to summary.\n",
      " |      \n",
      " |      Args:\n",
      " |          tag (str): Data identifier\n",
      " |          text_string (str): String to save\n",
      " |          global_step (int): Global step value to record\n",
      " |          walltime (float): Optional override default walltime (time.time())\n",
      " |            seconds after epoch of event\n",
      " |      Examples::\n",
      " |      \n",
      " |          writer.add_text('lstm', 'This is an lstm', 0)\n",
      " |          writer.add_text('rnn', 'This is an rnn', 10)\n",
      " |  \n",
      " |  add_video(self, tag, vid_tensor, global_step=None, fps=4, walltime=None)\n",
      " |      Add video data to summary.\n",
      " |      \n",
      " |      Note that this requires the ``moviepy`` package.\n",
      " |      \n",
      " |      Args:\n",
      " |          tag (str): Data identifier\n",
      " |          vid_tensor (torch.Tensor): Video data\n",
      " |          global_step (int): Global step value to record\n",
      " |          fps (float or int): Frames per second\n",
      " |          walltime (float): Optional override default walltime (time.time())\n",
      " |            seconds after epoch of event\n",
      " |      Shape:\n",
      " |          vid_tensor: :math:`(N, T, C, H, W)`. The values should lie in [0, 255] for type `uint8` or [0, 1] for type `float`.\n",
      " |  \n",
      " |  close(self)\n",
      " |  \n",
      " |  flush(self)\n",
      " |      Flushes the event file to disk.\n",
      " |      Call this method to make sure that all pending events have been written to\n",
      " |      disk.\n",
      " |  \n",
      " |  get_logdir(self)\n",
      " |      Returns the directory where event files will be written.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "help(SummaryWriter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter(\"logs\") # 创建一个logs文件夹，writer写的文件都在该文件夹下\n",
    "#writer.add_image()\n",
    "for i in range(100):\n",
    "    writer.add_scalar(\"y=2x\",2*i,i)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch-tb-profiler>=0.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow installation not found - running with reduced feature set.\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.14.0 at http://localhost:6006/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir=logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_PIL1:<class 'PIL.JpegImagePlugin.JpegImageFile'>, shape:; img_array1:<class 'numpy.ndarray'>, shape:(375, 500, 3)\n",
      "img_PIL2:<class 'PIL.JpegImagePlugin.JpegImageFile'>, shape:; img_array2:<class 'numpy.ndarray'>, shape:(412, 500, 3)\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "img_path1 = \"/storage/pt/AW_STUDY/pytorch-tutorial-tudui/hymenoptera_data/train/ants/5650366_e22b7e1065.jpg\" \n",
    "img_PIL1 = Image.open(img_path1)\n",
    "img_array1 = np.array(img_PIL1)\n",
    "print(f\"img_PIL1:{type(img_PIL1)}, shape:; img_array1:{type(img_array1)}, shape:{img_array1.shape}\")\n",
    "\n",
    "img_path2 = \"/storage/pt/AW_STUDY/pytorch-tutorial-tudui/hymenoptera_data/train/bees/17209602_fe5a5a746f.jpg\" \n",
    "img_PIL2 = Image.open(img_path2)\n",
    "img_array2 = np.array(img_PIL2)\n",
    "print(f\"img_PIL2:{type(img_PIL2)}, shape:; img_array2:{type(img_array2)}, shape:{img_array2.shape}\")\n",
    "\n",
    "writer = SummaryWriter(\"logs\") \n",
    "writer.add_image(\"test\",img_array1,1,dataformats=\"HWC\") # 1 表示该图片在第1步\n",
    "writer.add_image(\"test\",img_array2,2,dataformats=\"HWC\") # 2 表示该图片在第2步                   \n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov5_frog38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
