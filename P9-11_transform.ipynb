{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Transforms用途\n",
    "① Transforms当成工具箱的话，里面的class就是不同的工具。例如像totensor、resize这些工具。\n",
    "\n",
    "② Transforms拿一些特定格式的图片，经过Transforms里面的工具，获得我们想要的结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.3804, 0.3804, 0.3843,  ..., 0.3412, 0.3373, 0.3333],\n",
      "         [0.3765, 0.3804, 0.3843,  ..., 0.3529, 0.3490, 0.3451],\n",
      "         [0.3804, 0.3804, 0.3843,  ..., 0.3725, 0.3686, 0.3647],\n",
      "         ...,\n",
      "         [0.6078, 0.6078, 0.6118,  ..., 0.4627, 0.4627, 0.4627],\n",
      "         [0.5882, 0.5922, 0.5922,  ..., 0.4588, 0.4588, 0.4588],\n",
      "         [0.5804, 0.5804, 0.5843,  ..., 0.4549, 0.4549, 0.4549]],\n",
      "\n",
      "        [[0.4667, 0.4667, 0.4706,  ..., 0.4039, 0.4000, 0.3961],\n",
      "         [0.4706, 0.4667, 0.4706,  ..., 0.3922, 0.3882, 0.3843],\n",
      "         [0.4745, 0.4745, 0.4784,  ..., 0.3804, 0.3765, 0.3725],\n",
      "         ...,\n",
      "         [0.5961, 0.5961, 0.6000,  ..., 0.4588, 0.4588, 0.4588],\n",
      "         [0.5882, 0.5922, 0.5922,  ..., 0.4549, 0.4549, 0.4549],\n",
      "         [0.5804, 0.5804, 0.5804,  ..., 0.4510, 0.4510, 0.4510]],\n",
      "\n",
      "        [[0.4157, 0.4157, 0.4196,  ..., 0.3608, 0.3569, 0.3529],\n",
      "         [0.4196, 0.4157, 0.4196,  ..., 0.3569, 0.3529, 0.3490],\n",
      "         [0.4235, 0.4235, 0.4235,  ..., 0.3608, 0.3569, 0.3529],\n",
      "         ...,\n",
      "         [0.5608, 0.5608, 0.5647,  ..., 0.4392, 0.4392, 0.4392],\n",
      "         [0.5412, 0.5529, 0.5608,  ..., 0.4353, 0.4353, 0.4353],\n",
      "         [0.5333, 0.5412, 0.5608,  ..., 0.4314, 0.4314, 0.4314]]])\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "img_path = \"/storage/pt/AW_STUDY/pytorch-tutorial-tudui/hymenoptera_data/train/ants/5650366_e22b7e1065.jpg\"\n",
    "img = Image.open(img_path)\n",
    "\n",
    "tensor_trans = transforms.ToTensor()\n",
    "tensor_img = tensor_trans(img)\n",
    "print(tensor_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter(\"logs\") \n",
    "writer.add_image(\"Temsor_img\",tensor_img) \n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 归一化：output[c] = (input[c] - mean[c]) / std[c]\n",
    "如果原始像素值是 x，所在通道均值和方差都是0.5，则归一化后的值为 (x - 0.5) / 0.5\n",
    "### 其他：\n",
    "* .detach(): 这个操作是为了从计算图中分离出这个tensor,使其不再参与梯度计算。这是因为我们现在只需要获取tensor的值,而不需要进行任何训练或微调。\n",
    "* .cpu(): 这个操作是为了将tensor从GPU内存转移到CPU内存。这样做是为了使后续的numpy转换更加顺利,因为numpy无法直接操作GPU内存上的数据。\n",
    "* .numpy(): 这个操作是将tensor转换为numpy数组。numpy数组是一种更加通用的数据结构,可以用于各种数据处理和可视化操作。\n",
    "* .astype(np.uint8): 这个操作是将numpy数组的数据类型转换为无符号8位整数(uint8)。\n",
    "在图像处理中,像素值通常以8位整数(0-255)表示。将数组转换为uint8类型可以确保数据符合图像的标准格式。\n",
    "这一步也是必要的,因为在前一步中,tensor被转换为numpy数组后,数值可能还保留了小数部分。转换为uint8确保数值被截断到整数范围内,符合图像的要求。\n",
    "如果是64位图像，使用np.uint16而不是np.uint8,因为16位整数可以表示0-65535的范围,足以覆盖64位图像的像素值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "origin:tensor([[[0.3804, 0.3804, 0.3843,  ..., 0.3412, 0.3373, 0.3333],\n",
      "         [0.3765, 0.3804, 0.3843,  ..., 0.3529, 0.3490, 0.3451],\n",
      "         [0.3804, 0.3804, 0.3843,  ..., 0.3725, 0.3686, 0.3647],\n",
      "         ...,\n",
      "         [0.6078, 0.6078, 0.6118,  ..., 0.4627, 0.4627, 0.4627],\n",
      "         [0.5882, 0.5922, 0.5922,  ..., 0.4588, 0.4588, 0.4588],\n",
      "         [0.5804, 0.5804, 0.5843,  ..., 0.4549, 0.4549, 0.4549]],\n",
      "\n",
      "        [[0.4667, 0.4667, 0.4706,  ..., 0.4039, 0.4000, 0.3961],\n",
      "         [0.4706, 0.4667, 0.4706,  ..., 0.3922, 0.3882, 0.3843],\n",
      "         [0.4745, 0.4745, 0.4784,  ..., 0.3804, 0.3765, 0.3725],\n",
      "         ...,\n",
      "         [0.5961, 0.5961, 0.6000,  ..., 0.4588, 0.4588, 0.4588],\n",
      "         [0.5882, 0.5922, 0.5922,  ..., 0.4549, 0.4549, 0.4549],\n",
      "         [0.5804, 0.5804, 0.5804,  ..., 0.4510, 0.4510, 0.4510]],\n",
      "\n",
      "        [[0.4157, 0.4157, 0.4196,  ..., 0.3608, 0.3569, 0.3529],\n",
      "         [0.4196, 0.4157, 0.4196,  ..., 0.3569, 0.3529, 0.3490],\n",
      "         [0.4235, 0.4235, 0.4235,  ..., 0.3608, 0.3569, 0.3529],\n",
      "         ...,\n",
      "         [0.5608, 0.5608, 0.5647,  ..., 0.4392, 0.4392, 0.4392],\n",
      "         [0.5412, 0.5529, 0.5608,  ..., 0.4353, 0.4353, 0.4353],\n",
      "         [0.5333, 0.5412, 0.5608,  ..., 0.4314, 0.4314, 0.4314]]])\n",
      "tensor(0.3804)\n",
      "tensor(-0.2392)\n",
      "tensor shape:torch.Size([3, 375, 500])\n",
      "size(0):3\n",
      "denorm:tensor([[[0.3804, 0.3804, 0.3843,  ..., 0.3412, 0.3373, 0.3333],\n",
      "         [0.3765, 0.3804, 0.3843,  ..., 0.3529, 0.3490, 0.3451],\n",
      "         [0.3804, 0.3804, 0.3843,  ..., 0.3725, 0.3686, 0.3647],\n",
      "         ...,\n",
      "         [0.6078, 0.6078, 0.6118,  ..., 0.4627, 0.4627, 0.4627],\n",
      "         [0.5882, 0.5922, 0.5922,  ..., 0.4588, 0.4588, 0.4588],\n",
      "         [0.5804, 0.5804, 0.5843,  ..., 0.4549, 0.4549, 0.4549]],\n",
      "\n",
      "        [[0.4667, 0.4667, 0.4706,  ..., 0.4039, 0.4000, 0.3961],\n",
      "         [0.4706, 0.4667, 0.4706,  ..., 0.3922, 0.3882, 0.3843],\n",
      "         [0.4745, 0.4745, 0.4784,  ..., 0.3804, 0.3765, 0.3725],\n",
      "         ...,\n",
      "         [0.5961, 0.5961, 0.6000,  ..., 0.4588, 0.4588, 0.4588],\n",
      "         [0.5882, 0.5922, 0.5922,  ..., 0.4549, 0.4549, 0.4549],\n",
      "         [0.5804, 0.5804, 0.5804,  ..., 0.4510, 0.4510, 0.4510]],\n",
      "\n",
      "        [[0.4157, 0.4157, 0.4196,  ..., 0.3608, 0.3569, 0.3529],\n",
      "         [0.4196, 0.4157, 0.4196,  ..., 0.3569, 0.3529, 0.3490],\n",
      "         [0.4235, 0.4235, 0.4235,  ..., 0.3608, 0.3569, 0.3529],\n",
      "         ...,\n",
      "         [0.5608, 0.5608, 0.5647,  ..., 0.4392, 0.4392, 0.4392],\n",
      "         [0.5412, 0.5529, 0.5608,  ..., 0.4353, 0.4353, 0.4353],\n",
      "         [0.5333, 0.5412, 0.5608,  ..., 0.4314, 0.4314, 0.4314]]])\n",
      "tensor(0.3804)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# help(torch.tensor)\n",
    "\n",
    "img_path = \"/storage/pt/AW_STUDY/pytorch-tutorial-tudui/hymenoptera_data/train/ants/5650366_e22b7e1065.jpg\"\n",
    "img = Image.open(img_path)\n",
    "\n",
    "# 不需要 SummaryWriter 来保存图片到本地\n",
    "# writer = SummaryWriter(\"logs\") \n",
    "\n",
    "c_mean, c_std = [0.5,0.5,0.5], [0.5,0.5,0.5]\n",
    "\n",
    "tensor_trans = transforms.ToTensor() \n",
    "img_tensor = tensor_trans(img)  \n",
    "print(f\"origin:{img_tensor}\")\n",
    "\n",
    "print(img_tensor[0][0][0])\n",
    "tensor_norm = transforms.Normalize(c_mean, c_std) # input[channel]=(input[channel]-mean[channel])/std[channel]            \n",
    "img_norm = tensor_norm(img_tensor)  \n",
    "print(img_norm[0][0][0])\n",
    "print(f\"tensor shape:{img_tensor.shape}\")  # CHW\n",
    "print(f\"size(0):{img_tensor.size(0)}\")\n",
    "\n",
    "# # 计算图像的均值和标准差\n",
    "# img_mean = img_tensor.mean(dim=[1, 2])\n",
    "# img_std = img_tensor.std(dim=[1, 2])\n",
    "\n",
    "# print(\"Image mean:\", img_mean)\n",
    "# print(\"Image std:\", img_std)\n",
    "\n",
    "# print(f\"norm:{img_norm}\")\n",
    "# 手动实现transforms.Normalize.inverse()\n",
    "denorm_img_tensor = img_norm.clone()\n",
    "for c in range(img_tensor.size(0)):\n",
    "    denorm_img_tensor[c] = denorm_img_tensor[c]*c_std[c] + c_mean[c]\n",
    "# denorm_img_tensor = denorm_img_tensor*0.5+0.5\n",
    "print(f\"denorm:{denorm_img_tensor}\")\n",
    "print(denorm_img_tensor[0][0][0])\n",
    "\n",
    "# 保存原始张量图像到本地\n",
    "# 将张量转换为图像格式\n",
    "# img_tensor = img_tensor.mul(0.5).add(0.5).mul(255).clamp(0, 255).permute(1, 2, 0).to('cpu', torch.uint8).numpy()\n",
    "# denorm_img = denorm_img_tensor.mul(255).permute(1, 2, 0).to('cpu', torch.uint8).numpy()\n",
    "image_array = denorm_img_tensor.detach().cpu().numpy()\n",
    "image = Image.fromarray((image_array.transpose(1, 2, 0)*255).astype(np.uint8))\n",
    "\n",
    "\n",
    "# 使用 OpenCV 保存图像\n",
    "# cv2.imwrite('./img_save/img_denorm_tensor.jpg', denorm_img)\n",
    "# 使用PIL保存图像\n",
    "image.save('./img_save/img_denorm_tensor.jpg')\n",
    "\n",
    "\n",
    "# 不需要关闭 writer，因为我们没有使用它\n",
    "# writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape:torch.Size([3, 3, 3]), Original Tensor:tensor([[[ 1.,  2.,  3.],\n",
      "         [ 4.,  5.,  6.],\n",
      "         [ 7.,  8.,  9.]],\n",
      "\n",
      "        [[10., 11., 12.],\n",
      "         [13., 14., 15.],\n",
      "         [16., 17., 18.]],\n",
      "\n",
      "        [[19., 20., 21.],\n",
      "         [22., 23., 24.],\n",
      "         [25., 26., 27.]]])\n",
      "type:<class 'torch.Tensor'>, img_norm:tensor([[[ 1.,  3.,  5.],\n",
      "         [ 7.,  9., 11.],\n",
      "         [13., 15., 17.]],\n",
      "\n",
      "        [[19., 21., 23.],\n",
      "         [25., 27., 29.],\n",
      "         [31., 33., 35.]],\n",
      "\n",
      "        [[37., 39., 41.],\n",
      "         [43., 45., 47.],\n",
      "         [49., 51., 53.]]])\n",
      "type:<class 'torch.Tensor'>, img_denorm:tensor([[[ 1.,  2.,  3.],\n",
      "         [ 4.,  5.,  6.],\n",
      "         [ 7.,  8.,  9.]],\n",
      "\n",
      "        [[10., 11., 12.],\n",
      "         [13., 14., 15.],\n",
      "         [16., 17., 18.]],\n",
      "\n",
      "        [[19., 20., 21.],\n",
      "         [22., 23., 24.],\n",
      "         [25., 26., 27.]]])\n"
     ]
    }
   ],
   "source": [
    "# 测试tensor的操作\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "# 创建一个3x3x3的测试Tensor\n",
    "test_tensor = torch.tensor([[[1, 2, 3], \n",
    "                            [4, 5, 6],\n",
    "                            [7, 8, 9]],\n",
    "                           [[10, 11, 12],\n",
    "                            [13, 14, 15],\n",
    "                            [16, 17, 18]],\n",
    "                           [[19, 20, 21],\n",
    "                            [22, 23, 24],\n",
    "                            [25, 26, 27]]]).float()\n",
    "\n",
    "print(f\"shape:{test_tensor.shape}, Original Tensor:{test_tensor}\")\n",
    "\n",
    "tensor_norm = transforms.Normalize([0.5,0.5,0.5],[0.5,0.5,0.5]) # input[channel]=(input[channel]-mean[channel])/std[channel]            \n",
    "img_norm = tensor_norm(test_tensor)  \n",
    "print(f\"type:{type(img_norm)}, img_norm:{img_norm}\")\n",
    "\n",
    "img_denorm = img_norm*0.5 + 0.5\n",
    "print(f\"type:{type(img_denorm)}, img_denorm:{img_denorm}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resize裁剪"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x375 at 0x7F439868D5E0>\n",
      "torch.Size([3, 512, 682])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# help(torch.tensor)\n",
    "\n",
    "img_path = \"/storage/pt/AW_STUDY/pytorch-tutorial-tudui/hymenoptera_data/train/ants/5650366_e22b7e1065.jpg\"\n",
    "img = Image.open(img_path)\n",
    "print(img)\n",
    "\n",
    "trans_totensor = transforms.ToTensor() \n",
    "img_tensor = trans_totensor(img)  \n",
    "\n",
    "trans_resize = transforms.Resize((512,512)) #\n",
    "trans_resize_2 = transforms.Resize(512) # 等比缩放\n",
    "# PIL数据类型的 img -> resize -> PIL数据类型的 img_resize\n",
    "# img_resize = trans_resize(img)\n",
    "img_resize = trans_resize_2(img)\n",
    "# PIL 数据类型的 PIL -> totensor -> img_resize tensor\n",
    "img_resize = trans_totensor(img_resize)\n",
    "print(img_resize.size()) # PIL类型的图片原始比例为 3×512×512，3通道\n",
    "\n",
    "def tensor_to_imgsave(tensor_img, save_path):\n",
    "    image_array = tensor_img.detach().cpu().numpy()\n",
    "    image = Image.fromarray((image_array.transpose(1, 2, 0)*255).astype(np.uint8))\n",
    "    image.save(save_path)\n",
    "\n",
    "tensor_to_imgsave(img_resize, \"./img_save/img_resize_scale.jpg\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x375 at 0x7F446C5095E0>\n",
      "(100, 312)\n",
      "(100, 312)\n",
      "(100, 312)\n",
      "(100, 312)\n",
      "(100, 312)\n",
      "(100, 312)\n",
      "(100, 312)\n",
      "(100, 312)\n",
      "(100, 312)\n",
      "(100, 312)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img_path = \"/storage/pt/AW_STUDY/pytorch-tutorial-tudui/hymenoptera_data/train/ants/5650366_e22b7e1065.jpg\"\n",
    "img = Image.open(img_path)\n",
    "print(img)\n",
    "\n",
    "# trans_totensor = transforms.ToTensor() \n",
    "# img_tensor = trans_totensor(img)  \n",
    "\n",
    "trans_resize = transforms.Resize((512, 512))\n",
    "trans_resize_2 = transforms.Resize(512) # 等比缩放\n",
    "trans_random = transforms.RandomCrop(312) # 随即裁剪成 312×312 的\n",
    "trans_random = transforms.RandomCrop((312,100))  # 指定随即裁剪的高和宽 \n",
    "\n",
    "# img_resize = trans_random(img)\n",
    "\n",
    "# # Save the resized image\n",
    "# save_path = \"random_resized_image.jpg\"\n",
    "# img_resize.save(save_path)\n",
    "# print(f\"Resized image saved to: {save_path}\")\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    img_random_resize = trans_random(img)\n",
    "    img_random_resize.save(f\"./img_save/random_size_{i}.jpg\")\n",
    "    print(img_random_resize.size) # 宽和高\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov5_frog38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
